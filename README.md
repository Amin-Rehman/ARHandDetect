### How can we bring interactions with To Do into the physical world?

_How can we surprise our users and add whimsy to their experiences by giving them interactions that they aren’t asking for or that are possible in other productivity apps? Instead focusing on how can use tech like ML to bring info into todo, what if we used it to bring todo into our physical world?_

##### A proof of concept app for integrating ARKit and Hand detection for marking To Do items in Microsoft To Do complete.

### Tech used:
- **ARKit** - augmented reality using camera
- **SceneKit** - render 3D content
- **CoreML** - use machine learning models
- **Vision** - apply ML models to video

### What we did:
- Integrate ARKit into a view.
- Add 3d text into the view using SceneKit.
- Integrate hand detection ML model.
- Detect “touch” on a text node usnig CoreML & Vision.
- Add physics to 3d text when it is influenced by touch.

